{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import Parallel,delayed\n",
    "import multiprocessing\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('./..')\n",
    "sys.path.append('./../..')\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from common_utils import utils\n",
    "except:\n",
    "    from .common_utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_SOURCE = './../generated_data_v1/'\n",
    "CONFIG = None\n",
    "DIR_LOC = None\n",
    "CONFIG = None\n",
    "CONFIG_FILE = 'config.yaml'\n",
    "id_col = 'PanjivaRecordID'\n",
    "non_CoOcc_dict = {}\n",
    "numeric_col_stats = {}\n",
    "DATA_PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def aux_gen(\n",
    "    row,\n",
    "    discrete_dim_list, # Ordered\n",
    "    num_real_dims,\n",
    "    column_encoder,\n",
    "    num_samples = 10\n",
    "):\n",
    "    row_vals = row.values\n",
    "    num_cat = len(discrete_dim_list)\n",
    "    real_part = row_vals[-num_real_dims:]\n",
    "    cat_part = row_vals[:num_cat]\n",
    "    \n",
    "    nr = num_real_dims//2\n",
    "    ns = num_samples\n",
    "\n",
    "    # ======\n",
    "    a = max(1, num_real_dims//4)\n",
    "    b = max(1, num_real_dims//4)\n",
    "    \n",
    "    c = num_real_dims - (a + b)\n",
    "    # Adding -.5 to shift noise to be between -.5 to .5\n",
    "    noise = np.concatenate(\n",
    "        [np.random.random_sample([ns,a])  + -0.5, \n",
    "         np.random.random_sample([ns,b])  +  0.5, \n",
    "         np.zeros([ns,c])],\n",
    "        axis=1\n",
    "    )\n",
    "   \n",
    "    for i in range(ns):\n",
    "        np.random.shuffle(noise[i])\n",
    "    # ---\n",
    "    # noise shape [ ns, num_real_dims ]\n",
    "\n",
    "    part_r_duplicated = np.tile(real_part, ns).reshape([ns, num_real_dims])\n",
    "    part_r_duplicated = part_r_duplicated + noise\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------------------------------\n",
    "    # For categorical variables\n",
    "    # ------------------------------\n",
    "    \n",
    "    P = [ np.power( _/sum(discrete_dim_list), 0.75)  for _ in discrete_dim_list]  \n",
    "    P = [ _/sum(P) for _ in P]  \n",
    "    part_c_duplicated = np.tile(cat_part,ns).reshape([ns,num_cat])\n",
    "   \n",
    "    res = []\n",
    "    for i in range(ns):\n",
    "        _copy = np.array(row_vals)[:num_cat]\n",
    "        if num_cat < 3 :\n",
    "            pert_idx = np.random.choice( list(np.arange(num_cat)) , size=1, replace = False, p = P)\n",
    "        else:\n",
    "            pert_idx = np.random.choice(\n",
    "                list(np.arange(num_cat)),\n",
    "                size = np.random.randint(1, num_cat//2+1 ),\n",
    "                replace=False,\n",
    "                p = P\n",
    "            )\n",
    "\n",
    "        for j in pert_idx:\n",
    "            _copy[j] = np.random.choice(\n",
    "                np.arange(discrete_dim_list[j]),1\n",
    "            )\n",
    "        part_c_duplicated[i] = _copy\n",
    "        \n",
    "        \n",
    "    _samples = np.concatenate([part_c_duplicated, part_r_duplicated], axis=1)\n",
    "    row_vals = np.reshape(row.values,[1,-1] )\n",
    "\n",
    "    samples = np.concatenate([row_vals, _samples], axis=0)\n",
    "    sample_cat_part = samples[:, :num_cat]\n",
    "    samples_real_part = samples[:, -num_real_dims: ]\n",
    "\n",
    "    # =========================\n",
    "    # Do a 1-hot transformation\n",
    "    # Drop binary columns\n",
    "    # =========================\n",
    "\n",
    "    onehot_xformed = column_encoder.fit_transform(sample_cat_part)\n",
    "    onehot_xformed = onehot_xformed.astype(np.int)\n",
    "    print('>>> 1-0 part ', onehot_xformed.shape)\n",
    "    samples = np.concatenate([onehot_xformed, samples_real_part],axis=1)\n",
    "    \n",
    "    pos = samples[0]\n",
    "    neg = samples[1:]\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_neg_data (\n",
    "        train_df,\n",
    "        cat_domain_dims,\n",
    "        num_samples=10\n",
    "):\n",
    "    try:\n",
    "        del train_df['label']\n",
    "    except:\n",
    "        pass \n",
    " \n",
    "    num_cat = len(cat_domain_dims)\n",
    "    num_real = len(train_df.columns) - num_cat\n",
    "    \n",
    "    oh_encoder_list = []\n",
    "    idx = 0\n",
    "    \n",
    "    for _ , dim in cat_domain_dims.items():\n",
    "        if dim ==2 :\n",
    "            _drop = 'first'\n",
    "        else:\n",
    "            _drop = None\n",
    "        name = \"oh_\"+str(idx) \n",
    "        oh_encoder = OneHotEncoder(\n",
    "            np.reshape( list(range(dim)),[1,-1] ),\n",
    "            sparse=False,\n",
    "            drop=_drop\n",
    "        ) \n",
    "        oh_encoder_list.append((name, oh_encoder, [idx]))\n",
    "        idx +=1\n",
    "    column_encoder = ColumnTransformer(\n",
    "        oh_encoder_list\n",
    "    )\n",
    "                                \n",
    "    discrete_dim_list = list(cat_domain_dims.values())\n",
    "    n_jobs = multiprocessing.cpu_count()\n",
    "    \n",
    "    res = Parallel(n_jobs)(delayed(aux_gen)(\n",
    "            row, discrete_dim_list, num_real, column_encoder, num_samples\n",
    "        ) for i,row in tqdm(train_df.iterrows(), total=train_df.shape[0])\n",
    "    )\n",
    "      \n",
    "    pos = []\n",
    "    neg = []\n",
    "    for r in res:\n",
    "        pos.append(r[0])\n",
    "        neg.append(r[1])\n",
    "\n",
    "    pos = np.array(pos)\n",
    "    neg = np.array(neg)\n",
    "\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_config(_DIR = None):\n",
    "    global DIR\n",
    "    global CONFIG\n",
    "    global CONFIG_FILE\n",
    "    global use_cols\n",
    "    global freq_bound\n",
    "    global num_neg_samples_ape\n",
    "    global save_dir\n",
    "    global column_value_filters\n",
    "    global num_neg_samples\n",
    "    global NUMERIC_COLUMNS\n",
    "    global id_col\n",
    "    global DISCRETE_COLUMNS\n",
    "    global DATA_PATH\n",
    "    global DATA_SOURCE\n",
    "    \n",
    "    with open(CONFIG_FILE) as f:\n",
    "        CONFIG = yaml.safe_load(f)\n",
    "    \n",
    "    DATA_PATH = os.path.join(DATA_SOURCE, DIR)\n",
    "    if _DIR is not None:\n",
    "        DIR = _DIR\n",
    "        CONFIG['DIR'] = _DIR\n",
    "    else:\n",
    "        DIR = CONFIG['DIR']\n",
    "\n",
    "    DATA_PATH = os.path.join(DATA_SOURCE, DIR)\n",
    "    save_dir =  CONFIG['save_dir']\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    save_dir = os.path.join(\n",
    "        CONFIG['save_dir'],\n",
    "        DIR\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "        \n",
    "    use_cols = CONFIG[DIR]['use_cols']\n",
    " \n",
    "    NUMERIC_COLUMNS = CONFIG[DIR]['numeric_columns']\n",
    "    _cols = list(use_cols)\n",
    "    _cols.remove(id_col)\n",
    "    for nc in NUMERIC_COLUMNS:\n",
    "        _cols.remove(nc)\n",
    "        \n",
    "    DISCRETE_COLUMNS = list(sorted(_cols))\n",
    "    return \n",
    "\n",
    "def fetch_data_sets():\n",
    "    global DATA_PATH\n",
    "    df_train = pd.read_csv(os.path.join(DATA_PATH,'train_data.csv'),index_col=None)\n",
    "    df_test = pd.read_csv(os.path.join(DATA_PATH,'test_data.csv'),index_col=None)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_anomalies():\n",
    "    global DATA_PATH\n",
    "    df_anomalies = pd.read_csv(os.path.join(DATA_PATH,'gen_anomalies.csv'),index_col=None)\n",
    "    return df_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'us_import1'\n",
    "set_up_config(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the numeric values\n",
    "def normalize(val,_min,_max):\n",
    "    return (val-_min)/(_max - _min)\n",
    "\n",
    "df_train, df_test = fetch_data_sets()\n",
    "df_anomalies = fetch_anomalies()\n",
    "for nc in NUMERIC_COLUMNS:\n",
    "    _max = np.max(df_train[nc])\n",
    "    _min = np.min(df_train[nc])\n",
    "    df_train[nc] =  df_train[nc].parallel_apply(normalize, args=(_min,_max,))\n",
    "    df_test[nc] =  df_test[nc].parallel_apply(normalize, args=(_min,_max,))\n",
    "    df_anomalies[nc] = df_anomalies[nc].parallel_apply(normalize, args=(_min,_max,))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data_01(df, cat_domain_dims):\n",
    "    global DISCRETE_COLUMNS\n",
    "    global id_col\n",
    "    \n",
    "    try:\n",
    "        del df[id_col]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_cat = len(cat_domain_dims)\n",
    "    num_real = len(df.columns) - num_cat\n",
    "    \n",
    "    oh_encoder_list = []\n",
    "    idx = 0\n",
    "    \n",
    "    for _ , dim in cat_domain_dims.items():\n",
    "        if dim ==2 :\n",
    "            _drop = 'first'\n",
    "        else:\n",
    "            _drop = None\n",
    "        name = \"oh_\"+str(idx) \n",
    "        oh_encoder = OneHotEncoder(\n",
    "            np.reshape(list(range(dim)),[1,-1]),\n",
    "            sparse=False,\n",
    "            drop=_drop\n",
    "        ) \n",
    "       \n",
    "        oh_encoder_list.append((name, oh_encoder, [idx]))\n",
    "        idx +=1\n",
    "        \n",
    "    column_encoder = ColumnTransformer(\n",
    "        oh_encoder_list\n",
    "    )\n",
    "    samples = df.values\n",
    "    print(samples[0])\n",
    "    sample_cat_part = samples[:, :num_cat]\n",
    "    samples_real_part = samples[:, -num_real: ]\n",
    "    onehot_xformed = column_encoder.fit_transform(sample_cat_part)\n",
    "    onehot_xformed = onehot_xformed.astype(np.int)\n",
    "    samples = np.concatenate([onehot_xformed, samples_real_part],axis=1)\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dims_df = pd.read_csv(os.path.join(DATA_PATH,'data_dimensions.csv'),index_col=None)\n",
    "cat_domain_dims = { k:v for k,v in zip(domain_dims_df['column'],domain_dims_df['dimension']) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del df_train['PanjivaRecordID']\n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73635/73635 [07:22<00:00, 166.58it/s]\n"
     ]
    }
   ],
   "source": [
    "pos, neg = generate_pos_neg_data (\n",
    "        df_train,\n",
    "        cat_domain_dims,\n",
    "        num_samples=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.62000000e+02  1.31100000e+03  1.19000000e+02  1.36000000e+02\n",
      "  8.00000000e+00  5.00000000e+00  6.10000000e+01  7.32000000e+02\n",
      "  2.49185201e-03 -2.30894577e-07 -2.28301452e-10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.19000000e+02 5.81000000e+02 3.54000000e+02 4.20000000e+01\n",
      " 2.50000000e+01 6.50000000e+01 1.40000000e+01 2.74800000e+03\n",
      " 6.02409639e-03 5.77232264e-03 1.08897525e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:76: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories != 'auto':\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:85: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self.categories == 'auto':\n"
     ]
    }
   ],
   "source": [
    "anomalies_X = process_data_01(df_anomalies, cat_domain_dims)\n",
    "test_X = process_data_01(df_test, cat_domain_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62980, 8540)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15745, 8540)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        2.49185201e-03, -2.30894577e-07, -2.28301452e-10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(save_dir,'data_testX.npy')\n",
    "np.save(file_path,test_X,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
