{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "import sys\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./..')\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'normal.': 97278,\n",
       "         'buffer_overflow.': 30,\n",
       "         'loadmodule.': 9,\n",
       "         'perl.': 3,\n",
       "         'neptune.': 107201,\n",
       "         'smurf.': 280790,\n",
       "         'guess_passwd.': 53,\n",
       "         'pod.': 264,\n",
       "         'teardrop.': 979,\n",
       "         'portsweep.': 1040,\n",
       "         'ipsweep.': 1247,\n",
       "         'land.': 21,\n",
       "         'ftp_write.': 8,\n",
       "         'back.': 2203,\n",
       "         'imap.': 12,\n",
       "         'satan.': 1589,\n",
       "         'phf.': 4,\n",
       "         'nmap.': 231,\n",
       "         'multihop.': 7,\n",
       "         'warezmaster.': 20,\n",
       "         'warezclient.': 1020,\n",
       "         'spy.': 2,\n",
       "         'rootkit.': 10})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from common_utils import utils \n",
    "\n",
    "#----------------- \n",
    "# KDD data \n",
    "# ----------------\n",
    "\n",
    "with open('kddcup.names','r') as fh:\n",
    "    lines = fh.readlines()\n",
    "\n",
    "column_type_dict = {}\n",
    "for line in lines:\n",
    "    if ':' in line:\n",
    "        k = line.split(':')[0]\n",
    "        v = line.split(':')[1].strip()\n",
    "        v = v.strip('\\n')\n",
    "        v = v.strip('.')\n",
    "        column_type_dict[k] = v\n",
    "\n",
    "column_names = list(column_type_dict.keys())\n",
    "column_names.append('label')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'kddcup.data_10_percent_corrected',\n",
    "    index_col=None,\n",
    "    low_memory=False,\n",
    "    header=None,\n",
    "    names = column_names\n",
    ")\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "Counter(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['duration',\n",
       "  'src_bytes',\n",
       "  'dst_bytes',\n",
       "  'wrong_fragment',\n",
       "  'urgent',\n",
       "  'hot',\n",
       "  'num_failed_logins',\n",
       "  'num_compromised',\n",
       "  'root_shell',\n",
       "  'su_attempted',\n",
       "  'num_root',\n",
       "  'num_file_creations',\n",
       "  'num_shells',\n",
       "  'num_access_files',\n",
       "  'num_outbound_cmds',\n",
       "  'count',\n",
       "  'srv_count',\n",
       "  'serror_rate',\n",
       "  'srv_serror_rate',\n",
       "  'rerror_rate',\n",
       "  'srv_rerror_rate',\n",
       "  'same_srv_rate',\n",
       "  'diff_srv_rate',\n",
       "  'srv_diff_host_rate',\n",
       "  'dst_host_count',\n",
       "  'dst_host_srv_count',\n",
       "  'dst_host_same_srv_rate',\n",
       "  'dst_host_diff_srv_rate',\n",
       "  'dst_host_same_src_port_rate',\n",
       "  'dst_host_srv_diff_host_rate',\n",
       "  'dst_host_serror_rate',\n",
       "  'dst_host_srv_serror_rate',\n",
       "  'dst_host_rerror_rate',\n",
       "  'dst_host_srv_rerror_rate'],\n",
       " ['protocol_type',\n",
       "  'service',\n",
       "  'flag',\n",
       "  'land',\n",
       "  'logged_in',\n",
       "  'is_host_login',\n",
       "  'is_guest_login'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [ _ for _, v in column_type_dict.items() if v == 'symbolic']\n",
    "real_value_columns = [ _ for _, v in column_type_dict.items() if v == 'continuous']\n",
    "\n",
    "real_value_columns,categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107201, 97278)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_class = ['neptune.']\n",
    "anomaly_class= ['normal.']\n",
    "\n",
    "df_normal =  df.loc[df['label'].isin(normal_class)]\n",
    "df_anomalies = df.loc[df['label'].isin(anomaly_class)]\n",
    "\n",
    "len(df_normal),len(df_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "                    \n",
    "df_anomalies['label'] = 1\n",
    "df_normal['label'] = 0\n",
    "\n",
    "master_df = df_normal.append(df_anomalies,ignore_index=True)\n",
    "master_df = master_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  protocol_type Number of valid values 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:05<00:35,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  service Number of valid values 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:11<00:29,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  flag Number of valid values 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:17<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  land Number of valid values 2\n",
      " -->  logged_in Number of valid values 2\n",
      " -->  is_host_login Number of valid values 1\n",
      " -->  is_guest_login Number of valid values 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_with_id( row , ref_dict, col):\n",
    "    value =  row[col]\n",
    "    if value not in ref_dict.keys():\n",
    "        row[col] = None\n",
    "    else:\n",
    "        row[col] = ref_dict[value]\n",
    "    return row\n",
    "\n",
    "\n",
    "single_value_cols = []\n",
    "target_columns = list(categorical_columns)\n",
    "entity_count ={}\n",
    "for i in tqdm(range(len(target_columns))):\n",
    "    \n",
    "    column = target_columns[i]\n",
    "    valid_values = sorted(set(master_df[column]))\n",
    "    val2id_dict = { \n",
    "        e[1]:e[0] for e in enumerate(valid_values,0)\n",
    "    }\n",
    "    print(' --> ', column, 'Number of valid values', len(val2id_dict))\n",
    "    \n",
    "    if len(val2id_dict) == 1 :\n",
    "        single_value_cols.append(column)\n",
    "        #categorical_columns.remove(column)\n",
    "        continue\n",
    "    entity_count[column] = len(val2id_dict)\n",
    "    if len(val2id_dict) == 2 : continue\n",
    "    master_df = master_df.parallel_apply(\n",
    "        replace_with_id,\n",
    "        axis=1,\n",
    "        args = (val2id_dict, column,)\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_host_login']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_guest_login']\n"
     ]
    }
   ],
   "source": [
    "# Normalize the values\n",
    "def normalize_minmax(value, _max, _min):\n",
    "    return (value - _min)/(_max -_min)\n",
    "\n",
    "for column in real_value_columns:\n",
    "    _min = min(master_df[column])\n",
    "    _max = max(master_df[column])\n",
    "    if _max == _min: \n",
    "        continue\n",
    "    master_df[column] = master_df[column].parallel_apply(normalize_minmax, args= (_max,_min, ))\n",
    "    \n",
    "\n",
    "master_df = master_df.dropna()\n",
    "for s in single_value_cols:\n",
    "    del master_df[s]\n",
    "    try:\n",
    "        categorical_columns.remove(s)\n",
    "    except:\n",
    "        pass\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_guest_login', 'count',\n",
       "       'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
       "       'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
       "       'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
       "       'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
       "       'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
       "       'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
       "       'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = categorical_columns + real_value_columns + ['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Keep 2 versions\n",
    "# 1. one hot encoded\n",
    "# 2. not one hot enocoded\n",
    "\n",
    "def create_10_version( df, cat_columns):\n",
    "    global real_value_columns\n",
    "    label_Col = 'label'\n",
    "    df1 = df.copy() \n",
    "    for cc in cat_columns:\n",
    "        if entity_count[cc] == 2 :\n",
    "            _drop_first = True\n",
    "        else:\n",
    "            _drop_first = False\n",
    "        df1 = pd.get_dummies(df1, columns = [cc],drop_first = _drop_first)\n",
    "        \n",
    "    all_columns=list(df1.columns)\n",
    "    disc_columns = [ c for c in all_columns if c != 'label' and c not in real_value_columns]\n",
    "    ord_cols = disc_columns + real_value_columns + ['label']\n",
    "    return df1[ord_cols]\n",
    "\n",
    "\n",
    "master_df_1 = create_10_version( master_df, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = categorical_columns + real_value_columns + ['label']\n",
    "master_df = master_df[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size {:.3f} 71.84098625183105  MB \n",
      "Size {:.3f} 42.00315189361572  MB \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.00315189361572"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the files\n",
    "from pathlib import Path\n",
    "save_dir = 'processed'\n",
    "path_obj = Path(save_dir)\n",
    "path_obj.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ===========================\n",
    "# Write out the dimensionality of the columns into a text file\n",
    "# ============================\n",
    "\n",
    "col_name_list = []\n",
    "dimensionality = []\n",
    "data =[]\n",
    "for c in categorical_columns:\n",
    "    col_name_list.append(c)\n",
    "    v = len(set(master_df[c]))\n",
    "    dimensionality.append(v)\n",
    "    data.append((c,v)) \n",
    "df_data_dimensions = pd.DataFrame(\n",
    "    data = data,\n",
    "    columns=['column','dimension']\n",
    ")\n",
    "\n",
    "df_data_dimensions\n",
    "\n",
    "\n",
    "# Save metadata\n",
    "f_name = 'data_dimensions.csv'\n",
    "f_path = os.path.join(save_dir, f_name )\n",
    "df_data_dimensions.to_csv(f_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "utils.save_csv(master_df_1, os.path.join(save_dir,'data_onehot.csv'))\n",
    "utils.save_csv(master_df, os.path.join(save_dir,'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
