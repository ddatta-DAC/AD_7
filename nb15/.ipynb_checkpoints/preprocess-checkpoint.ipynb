{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "import sys\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./..')\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from common_utils import utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------- \n",
    "# UNSW NB 15 data \n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers_file = './NUSW-NB15_features.csv'\n",
    "features_df = pd.read_csv(column_headers_file,index_col=None,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No.', 'Name', 'Type ', 'Description'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df[['Name','Type ']]\n",
    "features_df = features_df.rename(columns={'Type ':'Type'})\n",
    "features_df['Name']=features_df['Name'].apply(str.lower)\n",
    "features_df['Type']=features_df['Type'].apply(str.lower)\n",
    "features_df = features_df.append({'Name':'rate','Type':'float'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_columns = [\n",
    "    'srcip','dstip','dsport','sport','stime','ltime'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcip\n",
      "dstip\n",
      "dsport\n",
      "sport\n",
      "stime\n",
      "ltime\n"
     ]
    }
   ],
   "source": [
    "columns = list(features_df['Name'])\n",
    "for r in invalid_columns:\n",
    "    print(r)\n",
    "    columns.remove(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =[ _.replace(' ','') for _ in columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('res_bdy_len', 'dmeansz', 'dintpkt', 'smeansz', 'sintpkt')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'res_bdy_len', 'dmeansz', 'dintpkt', 'smeansz', 'sintpkt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('UNSW_NB15_training-set.csv', index_col=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_ = {\n",
    "'dintpkt':'sinpkt',\n",
    "'sintpkt':'dinpkt',\n",
    "'smeansz':'smean',\n",
    "'dmeansz': 'dmean',\n",
    "'res_bdy_len' :'response_body_len',\n",
    "'ct_src_ ltm': 'ct_src_ltm'\n",
    "}\n",
    "features_df.replace(to_replace = replace_,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
       "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
       "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
       "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
       "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
       "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
       "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
       "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Normal': 56000,\n",
       "         'Backdoor': 1746,\n",
       "         'Analysis': 2000,\n",
       "         'Fuzzers': 18184,\n",
       "         'Shellcode': 1133,\n",
       "         'Reconnaissance': 10491,\n",
       "         'Exploits': 33393,\n",
       "         'DoS': 12264,\n",
       "         'Worms': 130,\n",
       "         'Generic': 40000})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data_df['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_classes = ['Normal']\n",
    "anomaly_classes = [ _ for _ in set(data_df['attack_cat']) if _ not in ['Normal','Generic','Exploits','Fuzzers','DoS','Reconnaissance']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = data_df.loc[data_df['attack_cat'].isin(normal_classes)]\n",
    "anomaly_df = data_df.loc[data_df['attack_cat'].isin(anomaly_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5009,\n",
       " Counter({'Backdoor': 1746,\n",
       "          'Analysis': 2000,\n",
       "          'Shellcode': 1133,\n",
       "          'Worms': 130}))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomaly_df), Counter(anomaly_df['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "normal_df['label'] = 0\n",
    "anomaly_df['label'] = 1\n",
    "\n",
    "if len(normal_df) < len(anomaly_df):                  \n",
    "    anomaly_df = anomaly_df.sample (n=int(len(normal_df)))\n",
    "master_df = normal_df.append(anomaly_df,ignore_index=True)\n",
    "del master_df['id']\n",
    "del master_df['attack_cat']\n",
    "master_df = master_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_value_columns = []\n",
    "categorical_columns = []\n",
    "binary_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in master_df.columns:\n",
    "    if column in list(features_df['Name']):\n",
    "        _type = list(features_df.loc[features_df['Name']==column]['Type'])[0]\n",
    "        if _type =='integer' or _type =='float':\n",
    "            real_value_columns.append(column)\n",
    "        elif _type =='binary':\n",
    "            if column =='label':\n",
    "                continue\n",
    "            binary_columns.append(column)\n",
    "        elif _type=='nominal':\n",
    "            categorical_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proto', 'service', 'state']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,\n",
       " ['dur',\n",
       "  'spkts',\n",
       "  'dpkts',\n",
       "  'sbytes',\n",
       "  'dbytes',\n",
       "  'rate',\n",
       "  'sttl',\n",
       "  'dttl',\n",
       "  'sload',\n",
       "  'dload',\n",
       "  'sloss',\n",
       "  'dloss',\n",
       "  'sinpkt',\n",
       "  'dinpkt',\n",
       "  'sjit',\n",
       "  'djit',\n",
       "  'swin',\n",
       "  'stcpb',\n",
       "  'dtcpb',\n",
       "  'dwin',\n",
       "  'tcprtt',\n",
       "  'synack',\n",
       "  'ackdat',\n",
       "  'smean',\n",
       "  'dmean',\n",
       "  'trans_depth',\n",
       "  'response_body_len',\n",
       "  'ct_srv_src',\n",
       "  'ct_state_ttl',\n",
       "  'ct_dst_ltm',\n",
       "  'ct_src_dport_ltm',\n",
       "  'ct_dst_sport_ltm',\n",
       "  'ct_dst_src_ltm',\n",
       "  'ct_ftp_cmd',\n",
       "  'ct_flw_http_mthd',\n",
       "  'ct_src_ltm',\n",
       "  'ct_srv_dst'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_value_columns),real_value_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_ftp_login', 'is_sm_ips_ports']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_with_id( row , ref_dict, col):\n",
    "    value =  row[col]\n",
    "    if value not in ref_dict.keys():\n",
    "        row[col] = None\n",
    "    else:\n",
    "        row[col] = ref_dict[value]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proto', 'service', 'state', 'is_ftp_login', 'is_sm_ips_ports']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_value_cols = []\n",
    "target_columns = list(categorical_columns)+ list(binary_columns)\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  proto Number of valid values 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  service Number of valid values 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:04,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  state Number of valid values 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:04<00:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  is_ftp_login Number of valid values 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->  is_sm_ips_ports Number of valid values 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "entity_count = {}\n",
    "for i in tqdm(range(len(target_columns))):\n",
    "    \n",
    "    column = target_columns[i]\n",
    "    valid_values = sorted(set(master_df[column]))\n",
    "    val2id_dict = { \n",
    "        e[1]:e[0] for e in enumerate(valid_values,0)\n",
    "    }\n",
    "    print(' --> ', column, 'Number of valid values', len(val2id_dict))\n",
    "    \n",
    "    if len(val2id_dict) == 1 :\n",
    "        print(column )\n",
    "        single_value_cols.append(column)\n",
    "        #categorical_columns.remove(column)\n",
    "        continue\n",
    "        \n",
    "    entity_count[column] = len(val2id_dict)\n",
    "    if len(val2id_dict) == 2 : \n",
    "        continue\n",
    "    master_df = master_df.parallel_apply(\n",
    "        replace_with_id,\n",
    "        axis=1,\n",
    "        args = (val2id_dict, column,)\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = list(categorical_columns)+ list(binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dur\n",
      "> >0.09097899999999999>>>>\n",
      "  >  0.33234> 0.004626>1.0047820.121478 \n",
      ">0.001037\n",
      " \n",
      "\n",
      " 0.001059\n",
      " 1.0838030.858152>0.647686\n",
      ">\n",
      "\n",
      ">> \n",
      ">   1.1070821.011978>0.001078>0.090099\n",
      " \n",
      "\n",
      ">  >>0.0010949999999999998>>\n",
      ">> \n",
      ">   > 0.273192999999999960.221439>  29.219688 0.60035699999999990.021119\n",
      "\n",
      "> 0.183253>>0.034270999999999996>>\n",
      "0.47800699999999996 0.935834\n",
      "0.001106  \n",
      "0.017412999999999998 \n",
      "\n",
      " \n",
      ">0.303252\n",
      ">0.0429420.9305370000000001>>\n",
      " \n",
      "0.466939999999999971.844831 \n",
      "\n",
      ">\n",
      " >>0.592684  3e-06\n",
      "\n",
      " 1.394902\n",
      "  10.145435\n",
      "0.0\n",
      "3e-060.21136\n",
      ">0.8663379999999999\n",
      "\n",
      "\n",
      " \n",
      "1.317599\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 59, in global_worker\n    return _func(x)\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 111, in wrapper\n    **kwargs\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/pandarallel/data_types/series.py\", line 20, in worker\n    return series.apply(func, *args, **kwargs)\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/pandas/core/series.py\", line 3848, in apply\n    mapped = lib.map_infer(values, f, convert=convert_dtype)\n  File \"pandas/_libs/lib.pyx\", line 2329, in pandas._libs.lib.map_infer\n  File \"/home/ddatta/anaconda3/envs/SG/lib/python3.7/site-packages/pandas/core/series.py\", line 3833, in f\n    return func(x, *args, **kwds)\n  File \"<ipython-input-56-23dc4f925202>\", line 4, in normalize_minmax\n    return (value - _min)/(_max -_min)\nTypeError: unsupported operand type(s) for -: 'float' and 'str'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-23dc4f925202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_minmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0minput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0moutput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                 \u001b[0mmap_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             )\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mprogress_bars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogresses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     return (\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Normalize the values\n",
    "def normalize_minmax(value, _max, _min):\n",
    "    if type(value) == str:\n",
    "        print('>', value)\n",
    "    return (value - _min)/(_max -_min)\n",
    "\n",
    "for column in real_value_columns:\n",
    "    master_df\n",
    "    _min = min(master_df.loc[master_df['label'] == 0])\n",
    "    _max = max(master_df.loc[master_df['label'] == 0])\n",
    "    if _max == _min: \n",
    "        continue\n",
    "    print(column)\n",
    "    master_df[column] = master_df[column].parallel_apply(normalize_minmax, args= (_max,_min, ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.121478\n",
       "1        0.649902\n",
       "2        1.623129\n",
       "3        1.681642\n",
       "4        0.449454\n",
       "           ...   \n",
       "61004    1.047423\n",
       "61005    1.265776\n",
       "61006    0.000005\n",
       "61007    0.227193\n",
       "61008    0.505762\n",
       "Name: dur, Length: 61009, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['proto', 'service', 'state', 'is_ftp_login', 'is_sm_ips_ports']\n"
     ]
    }
   ],
   "source": [
    "for s in single_value_cols:\n",
    "    del master_df[s]\n",
    "    try:\n",
    "        discrete_columns.remove(s)\n",
    "    except:\n",
    "        pass\n",
    "print(discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
       "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
       "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
       "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
       "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
       "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
       "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
       "       'ct_srv_dst', 'is_sm_ips_ports', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = discrete_columns + real_value_columns + ['label']\n",
    "master_df = master_df[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Keep 2 versions\n",
    "# 1. one hot encoded\n",
    "# 2. not one hot enocoded\n",
    "\n",
    "def create_10_version( df, cat_columns):\n",
    "    global real_value_columns\n",
    "    label_Col = 'label'\n",
    "    df1 = df.copy() \n",
    "    for cc in cat_columns:\n",
    "        if entity_count[cc] == 2 :\n",
    "            _drop_first = True\n",
    "        else:\n",
    "            _drop_first = False\n",
    "        df1 = pd.get_dummies(df1, columns = [cc], drop_first=_drop_first)\n",
    "    all_columns=list(df1.columns)\n",
    "    disc_columns = [ c for c in all_columns if c != 'label' and c not in real_value_columns]\n",
    "    ord_cols = disc_columns + real_value_columns + ['label']\n",
    "    return df1[ord_cols]\n",
    "\n",
    "\n",
    "master_df_1 = create_10_version( master_df, discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_ftp_login', 'is_sm_ips_ports']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the files\n",
    "from pathlib import Path\n",
    "save_dir = 'processed'\n",
    "path_obj = Path(save_dir)\n",
    "path_obj.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proto</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>state</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is_ftp_login</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_sm_ips_ports</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  dimension\n",
       "0            proto        133\n",
       "1          service         11\n",
       "2            state          9\n",
       "3     is_ftp_login          3\n",
       "4  is_sm_ips_ports          2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================\n",
    "# Write out the dimensionality of the columns into a text file\n",
    "# ============================\n",
    "\n",
    "col_name_list = []\n",
    "dimensionality = []\n",
    "data =[]\n",
    "for c in discrete_columns:\n",
    "    col_name_list.append(c)\n",
    "    v = len(set(master_df[c]))\n",
    "    dimensionality.append(v)\n",
    "    data.append((c,v)) \n",
    "    \n",
    "df_data_dimensions = pd.DataFrame(\n",
    "    data = data,\n",
    "    columns=['column','dimension']\n",
    ")\n",
    "\n",
    "df_data_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "f_name = 'data_dimensions.csv'\n",
    "f_path = os.path.join(save_dir, f_name )\n",
    "df_data_dimensions.to_csv(f_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size {:.3f} 50.26268672943115  MB \n",
      "Size {:.3f} 33.26605415344238  MB \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.26605415344238"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.save_csv(master_df_1, os.path.join(save_dir,'data_onehot.csv'))\n",
    "utils.save_csv(master_df, os.path.join(save_dir,'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df_1.columns)-37-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_value_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in real_value_columns:\n",
    "    if r not in list(master_df.columns):\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61009"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmp = pd.read_csv('./processed/data.csv')\n",
    "len(tmp.loc[tmp['label']==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39200.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7 * 56000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
